name: Scrape latest data

on:
  # push:
  workflow_dispatch:
  schedule:
    # 2:10 am Pacific Time
    - cron: '10 9 * * *'

jobs:
  scheduled:
    runs-on: ubuntu-latest
    steps:
    - name: Check out this repo
      uses: actions/checkout@v2
    #- name: Fetch latest data
    #  run: |-
    #    curl https://www.theguardian.com/science/rss >gsci.rss
    # sqlite-utils --csv feeds.db "select title,link,updated from links order by updated desc;"  >gscience.csv

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.8
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install feed-to-sqlite
        pip install sqlite-utils
    - name: Fetch latest data
      run: |-
        feed-to-sqlite feeds.db --table links https://www.theguardian.com/science/rss 
        feed-to-sqlite feeds.db --table links https://feeds.bbci.co.uk/news/science_and_environment/rss.xml?edition=us
        sqlite-utils --csv feeds.db "select title,link, \
          SUBSTR(published, 13, 4) || '-' || \
           CASE SUBSTR(published, 9, 3) \
            WHEN 'Jan' THEN '01' \
            WHEN 'Feb' THEN '02' \
            WHEN 'Mar' THEN '03' \
            WHEN 'Apr' THEN '04' \
            WHEN 'May' THEN '05' \
            WHEN 'Jun' THEN '06' \
            WHEN 'Jul' THEN '07' \
            WHEN 'Aug' THEN '08' \
            WHEN 'Sep' THEN '09' \
            WHEN 'Oct' THEN '10' \
            WHEN 'Nov' THEN '11' \
            WHEN 'Dec' THEN '12' \
           END \
           || '-' || \
           SUBSTR(published, 6, 2) || '-' || \
           SUBSTR(published, 18, 8) as 'pubdate' \
          from links order by pubdate;"  >gscience.csv
    - name: Commit and push if it changed
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        git commit -m "Latest data: ${timestamp}" || exit 0
        git push
